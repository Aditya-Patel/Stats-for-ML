{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMNISTDataset(dir):\n",
    "    df = pd.read_csv(dir)\n",
    "    Xdf = df.iloc[:, 1:].to_numpy()\n",
    "    ydf = df.iloc[:, 0].to_numpy()\n",
    "    return Xdf, ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cwd = os.getcwd() + '/mnist_train.csv'\n",
    "test_cwd = os.getcwd() + '/mnist_test.csv'\n",
    "\n",
    "X_train, y_train = CreateMNISTDataset(train_cwd)\n",
    "X_test, y_test = CreateMNISTDataset(test_cwd)\n",
    "\n",
    "X_ttrain, y_ttrain = tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)\n",
    "X_ttest, y_ttest = tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_labels = 10\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(600, activation = \"tanh\"),\n",
    "    keras.layers.Dense(450, activation = \"swish\"),\n",
    "    keras.layers.Dense(300, activation = \"tanh\"),\n",
    "    keras.layers.Dense(150, activation = \"swish\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 784)               3136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 600)               471000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 450)               270450    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               135300    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 926546 (3.53 MB)\n",
      "Trainable params: 924978 (3.53 MB)\n",
      "Non-trainable params: 1568 (6.12 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adafactor(weight_decay=1e-3)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 - 9s - loss: 0.4835 - accuracy: 0.8683 - val_loss: 0.2168 - val_accuracy: 0.9362 - 9s/epoch - 15ms/step\n",
      "Epoch 2/20\n",
      "600/600 - 8s - loss: 0.1934 - accuracy: 0.9426 - val_loss: 0.1609 - val_accuracy: 0.9537 - 8s/epoch - 13ms/step\n",
      "Epoch 3/20\n",
      "600/600 - 8s - loss: 0.1388 - accuracy: 0.9568 - val_loss: 0.1348 - val_accuracy: 0.9572 - 8s/epoch - 13ms/step\n",
      "Epoch 4/20\n",
      "600/600 - 8s - loss: 0.1075 - accuracy: 0.9678 - val_loss: 0.1207 - val_accuracy: 0.9619 - 8s/epoch - 13ms/step\n",
      "Epoch 5/20\n",
      "600/600 - 8s - loss: 0.0863 - accuracy: 0.9738 - val_loss: 0.1122 - val_accuracy: 0.9649 - 8s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "600/600 - 8s - loss: 0.0677 - accuracy: 0.9801 - val_loss: 0.1049 - val_accuracy: 0.9678 - 8s/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "600/600 - 8s - loss: 0.0566 - accuracy: 0.9827 - val_loss: 0.0998 - val_accuracy: 0.9686 - 8s/epoch - 13ms/step\n",
      "Epoch 8/20\n",
      "600/600 - 8s - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0969 - val_accuracy: 0.9701 - 8s/epoch - 13ms/step\n",
      "Epoch 9/20\n",
      "600/600 - 8s - loss: 0.0372 - accuracy: 0.9897 - val_loss: 0.0976 - val_accuracy: 0.9712 - 8s/epoch - 13ms/step\n",
      "Epoch 10/20\n",
      "600/600 - 8s - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9705 - 8s/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "600/600 - 8s - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0959 - val_accuracy: 0.9717 - 8s/epoch - 13ms/step\n",
      "Epoch 12/20\n",
      "600/600 - 8s - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.0951 - val_accuracy: 0.9728 - 8s/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "600/600 - 8s - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.1018 - val_accuracy: 0.9718 - 8s/epoch - 13ms/step\n",
      "Epoch 14/20\n",
      "600/600 - 8s - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.1100 - val_accuracy: 0.9695 - 8s/epoch - 13ms/step\n",
      "Epoch 15/20\n",
      "600/600 - 8s - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.1039 - val_accuracy: 0.9719 - 8s/epoch - 13ms/step\n",
      "Epoch 16/20\n",
      "600/600 - 8s - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.1014 - val_accuracy: 0.9738 - 8s/epoch - 13ms/step\n",
      "Epoch 17/20\n",
      "600/600 - 8s - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.1061 - val_accuracy: 0.9741 - 8s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "600/600 - 8s - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1105 - val_accuracy: 0.9728 - 8s/epoch - 13ms/step\n",
      "Epoch 19/20\n",
      "600/600 - 8s - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1090 - val_accuracy: 0.9741 - 8s/epoch - 13ms/step\n",
      "Epoch 20/20\n",
      "600/600 - 8s - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.1149 - val_accuracy: 0.9728 - 8s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_ttrain, y_ttrain,\n",
    "                 epochs=n_epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 verbose=2,\n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1246 - accuracy: 0.9730 - 735ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "future = model.evaluate(X_ttest, y_ttest, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
